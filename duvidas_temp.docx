# Relatório de Experimentos: Otimização de Modelo de Classificação de Imagens

**Data:** 29 de julho de 2025

**Objetivo:** Desenvolver um modelo de Rede Neural Convolucional (CNN) para classificação de imagens, partindo de uma arquitetura base e aplicando iterativamente técnicas para mitigar o overfitting e melhorar a capacidade de generalização do modelo em dados não vistos.

---

### **Configuração Geral**

Os experimentos foram conduzidos utilizando os seguintes hiperparâmetros e configurações base:

* **Otimizador:** `adam`
* **Função de Perda:** `sparse_categorical_crossentropy`
* **Métrica de Avaliação:** `accuracy`
* **Tamanho do Lote (Batch Size):** `32`
* **Divisão de Validação (Inicial):** 20% do conjunto de treino.

---

### **Fases do Experimento e Análise de Resultados**

#### **Teste 1: Modelo Baseline e Identificação de Overfitting**
* **Modificações:** Utilização de uma arquitetura CNN padrão com imagens de 64x64 pixels e uma camada de Dropout.
* **Resultados:**
    * Acurácia de Treino: `88.96%`
    * Acurácia de Validação: `78.21%`
* **Análise:** O modelo demonstrou uma alta capacidade de aprendizado nos dados de treino. No entanto, a queda de mais de 10 pontos percentuais na acurácia de validação indicou um **forte overfitting**, onde o modelo memorizou os dados de treino em vez de generalizar os padrões.

#### **Teste 2: Aumento da Regularização com Dropout Adicional**
* **Modificações:** Adição de uma segunda camada de `Dropout(0.5)` para aumentar a regularização.
* **Resultados:** Queda na acurácia de treino e de validação.
* **Análise:** A regularização aplicada foi excessiva, causando **underfitting**. O modelo ficou tão restrito que sua capacidade de aprender os padrões relevantes foi prejudicada, resultando em um desempenho inferior em todos os âmbitos.

#### **Teste 3: Aumento da Resolução das Imagens**
* **Modificações:** A resolução das imagens foi aumentada de 64x64 para 224x224.
* **Resultados:**
    * Acurácia de Treino: `90.57%`
    * Acurácia de Validação: `74.38%`
* **Análise:** Imagens maiores forneceram mais detalhes, permitindo que o modelo atingisse uma acurácia de treino ainda maior. Contudo, isso **agravou o overfitting**, aumentando a diferença entre a performance de treino e validação.

#### **Teste 4: Introdução de Data Augmentation Simples**
* **Modificações:** Aplicação de técnicas de aumento de dados (`RandomFlip` e `RandomRotation`).
* **Resultados:**
    * Acurácia de Treino: `~68%`
    * Acurácia de Validação: `~69%`
* **Análise:** O overfitting foi **efetivamente eliminado**, alinhando as métricas de treino e validação. No entanto, o custo foi uma **queda drástica na performance geral** do modelo (de ~78% para 69% na validação).

#### **Teste 5: Modificação do Dataset e Data Augmentation Agressiva**
* **Modificações:**
    1.  Agrupamento de 3 classes de vidro em uma única classe (`glass`).
    2.  Uso de uma técnica de augmentation mais poderosa e agressiva (`RandAugment` com `factor=0.5`).
* **Resultados:**
    * Acurácia de Validação: `61.99%`
    * Acurácia de Teste: `63.62%`
* **Análise:** A performance geral diminuiu ainda mais. A camada `RandAugment` com um fator de `0.5` mostrou-se **excessivamente agressiva**, causando forte underfitting.

#### **Teste 6: Ajuste Fino do Data Augmentation e Early Stopping**
* **Modificações:**
    1.  Redução da intensidade do `RandAugment` para `factor=0.2`.
    2.  Implementação de `EarlyStopping` para interromper o treino.
* **Resultados:**
    * Melhor Acurácia de Validação: `75.29%` (na 10ª época).
    * Acurácia de Teste Final: `73.32%`.
* **Análise:** A redução da intensidade da augmentation foi crucial, recuperando grande parte da performance perdida. O `EarlyStopping` foi configurado com `restore_best_weights=False`, fazendo com que os pesos finais não fossem os do melhor desempenho.

#### **Teste 7: Combinação de Técnicas de Regularização**
* **Modificações:**
    1.  Adição de regularização de kernel `L1L2` às camadas.
    2.  Ajuste da paciência (`patience`) do `EarlyStopping` para 3.
* **Resultados:**
    * Acurácia de Validação: `75.33%`.
    * Acurácia de Teste: `76.87%`.
* **Análise:** Esta abordagem produziu o **melhor resultado**. A combinação de um data augmentation mais suave (`factor=0.2`) com a regularização de kernel (`L1L2`) criou um modelo bem equilibrado. O overfitting foi controlado e a acurácia no conjunto de teste foi a mais alta de todos os experimentos.

---

### **Conclusão e Próximos Passos**

A série de experimentos demonstrou um